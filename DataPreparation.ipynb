{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtV9REDvD9Ol","executionInfo":{"status":"ok","timestamp":1703125203339,"user_tz":-420,"elapsed":6914,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}},"outputId":"560f8f10-f00c-44ec-a5cf-e4c3002624d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","\n","# Global Variables\n","RAW_DATASET_PATH = \"/content/drive/MyDrive/machine_learning/raw_dataset\"\n","SPLIT_DATASET_PATH = \"/content/drive/MyDrive/machine_learning/split_dataset\"\n","TRAIN_PATH = os.path.join(SPLIT_DATASET_PATH, 'train')\n","VAL_PATH = os.path.join(SPLIT_DATASET_PATH, 'val')\n","SPICES_LIST = os.listdir(RAW_DATASET_PATH)\n","NUM_OF_SPICES = len(SPICES_LIST)\n","\n","print('Spices total:', NUM_OF_SPICES)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5t_krZceEP8e","executionInfo":{"status":"ok","timestamp":1703125203341,"user_tz":-420,"elapsed":18,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}},"outputId":"19ca4adc-9a4b-4f2e-ecfe-a0b66c57fc4c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Spices total: 25\n"]}]},{"cell_type":"code","source":["# Function to count the number of images for each spice\n","def count_spices_images(dataset_path):\n","    index = 1\n","    total_images = 0\n","    print('-= Number of Images for Each Spice =-')\n","    for spices in SPICES_LIST:\n","        spices_path = os.path.join(dataset_path, spices)\n","        num_images = len(os.listdir(spices_path))\n","        print('{:2}. {:16} : {}'.format(index, spices, num_images))\n","        index += 1\n","        total_images += num_images\n","    print('\\nTotal images:', total_images)\n","\n","# Call the function with the raw dataset path\n","count_spices_images(RAW_DATASET_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nph99mDCHgxw","executionInfo":{"status":"ok","timestamp":1703125204723,"user_tz":-420,"elapsed":1392,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}},"outputId":"c5ad6ba4-161d-43d1-897f-8bc21c694137"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["-= Number of Images for Each Spice =-\n"," 1. kapulaga         : 100\n"," 2. biji_ketumbar    : 49\n"," 3. lada             : 100\n"," 4. serai            : 99\n"," 5. kunyit           : 100\n"," 6. lengkuas         : 128\n"," 7. kemiri           : 99\n"," 8. andaliman        : 90\n"," 9. daun_ketumbar    : 100\n","10. cabai            : 100\n","11. bawang_putih     : 92\n","12. cengkeh          : 123\n","13. adas_bintang     : 108\n","14. temulawak        : 100\n","15. jahe             : 100\n","16. daun_salam       : 99\n","17. biji_adas        : 100\n","18. wijen            : 100\n","19. asam_jawa        : 89\n","20. pala             : 99\n","21. kayu_manis       : 142\n","22. vanili           : 110\n","23. kayu_secang      : 101\n","24. bawang_merah     : 112\n","25. kencur           : 100\n","\n","Total images: 2540\n"]}]},{"cell_type":"code","source":["# Clearing the Train-Val directory\n","from shutil import rmtree\n","\n","def CleanDatasetDirectory(clean_data_path, train_path, val_path):  # Exclude the test_path parameter\n","    if os.path.exists(clean_data_path):  # Remove the old directory\n","        rmtree(clean_data_path)\n","\n","    # Create new empty directories\n","    for spice in SPICES_LIST:\n","        train_spice_path = os.path.join(train_path, spice)\n","        os.makedirs(train_spice_path)\n","\n","        val_spice_path = os.path.join(val_path, spice)\n","        os.makedirs(val_spice_path)\n","\n","    print('Finished emptying old data.')"],"metadata":{"id":"DcNjFW5JH51l","executionInfo":{"status":"ok","timestamp":1703125204724,"user_tz":-420,"elapsed":37,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Resizing data and saving in a temporary folder\n","from PIL import Image\n","\n","def ResizeAndSaveData(source, dest, spices_name, image_size):\n","    os.makedirs(dest, exist_ok=True)\n","    count = 0\n","    zeros_padding = 4\n","\n","    for spice_image in os.listdir(source):\n","        image_path = os.path.join(source, spice_image)\n","        img = Image.open(image_path).convert('RGB')\n","\n","        # Generate a new JPEG name with zero-padding\n","        jpeg_name = spices_name + str(count).zfill(zeros_padding) + \".jpeg\"\n","        image_dest_path = os.path.join(dest, jpeg_name)\n","\n","        # Resize the image and save it to the destination\n","        img.resize(image_size).save(image_dest_path)\n","\n","        count += 1\n","\n","    print('Data resizing and saving completed.')"],"metadata":{"id":"TApjfdLNHg5p","executionInfo":{"status":"ok","timestamp":1703125204725,"user_tz":-420,"elapsed":36,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Data Splitting Function (still Train-Dev Split using SPLIT_SIZE)\n","import random\n","from shutil import move\n","\n","def SplitDataAndPrint(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE, SPICES_NAME):  # You can use dev_size / test_size later\n","\n","    # Get a list of directories in the source folder\n","    dir_list = os.listdir(SOURCE)\n","    randomized_dir_list = random.sample(dir_list, len(dir_list))\n","\n","    # Remove 0 size images\n","    final_list = []\n","    for filename in randomized_dir_list:\n","        fullpath = os.path.join(SOURCE, filename)\n","        if os.path.getsize(fullpath) != 0:\n","            final_list.append(filename)\n","        else:\n","            print(\"{} is zero length, so ignoring.\".format(filename))\n","\n","    # Start Splitting (train-dev split)\n","    index_split = round(SPLIT_SIZE * len(final_list))\n","    for filename in final_list[:index_split]:\n","        source = os.path.join(SOURCE, filename)\n","        dest = os.path.join(TRAINING, filename)\n","        move(source, dest)\n","\n","    for filename in final_list[index_split:]:\n","        source = os.path.join(SOURCE, filename)\n","        dest = os.path.join(VALIDATION, filename)\n","        move(source, dest)\n","\n","    print('Data splitting completed for:', SPICES_NAME)"],"metadata":{"id":"mnl3JHhwI6xL","executionInfo":{"status":"ok","timestamp":1703125204725,"user_tz":-420,"elapsed":30,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Copy files to Train-Val Directory (Train-Val later when the dataset is large)\n","def CreateCleanDataset(data_path, train_path, val_path, image_size, split_size):  # Exclude test_path parameter\n","    temp_folder_path = '/tmp/convert_images'\n","\n","    for spice in SPICES_LIST:\n","        source_path = os.path.join(data_path, spice)\n","        train_spice_path = os.path.join(train_path, spice)\n","        val_spice_path = os.path.join(val_path, spice)\n","        # test_spice_path = os.path.join(test_path, spice)\n","\n","        # Resize and rename data\n","        ResizeAndSaveData(source_path, temp_folder_path, spice, image_size)\n","\n","        # Split data into training and validation sets\n","        SplitDataAndPrint(temp_folder_path, train_spice_path, val_spice_path, split_size, spice)"],"metadata":{"id":"xmLz6RKiJWfC","executionInfo":{"status":"ok","timestamp":1703125204726,"user_tz":-420,"elapsed":28,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["IMAGE_SIZE = (384, 384)\n","SPLIT_SIZE = 0.7\n","\n","CleanDatasetDirectory(SPLIT_DATASET_PATH, TRAIN_PATH, VAL_PATH)\n","CreateCleanDataset(RAW_DATASET_PATH, TRAIN_PATH, VAL_PATH, IMAGE_SIZE, SPLIT_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6rAg3ZTJv3Q","executionInfo":{"status":"ok","timestamp":1703125587050,"user_tz":-420,"elapsed":382350,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}},"outputId":"78f9a512-9695-41c0-cd2a-539319faca7f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished emptying old data.\n","Data resizing and saving completed.\n","Data splitting completed for: kapulaga\n","Data resizing and saving completed.\n","Data splitting completed for: biji_ketumbar\n","Data resizing and saving completed.\n","Data splitting completed for: lada\n","Data resizing and saving completed.\n","Data splitting completed for: serai\n","Data resizing and saving completed.\n","Data splitting completed for: kunyit\n","Data resizing and saving completed.\n","Data splitting completed for: lengkuas\n","Data resizing and saving completed.\n","Data splitting completed for: kemiri\n","Data resizing and saving completed.\n","Data splitting completed for: andaliman\n","Data resizing and saving completed.\n","Data splitting completed for: daun_ketumbar\n","Data resizing and saving completed.\n","Data splitting completed for: cabai\n","Data resizing and saving completed.\n","Data splitting completed for: bawang_putih\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Data resizing and saving completed.\n","Data splitting completed for: cengkeh\n","Data resizing and saving completed.\n","Data splitting completed for: adas_bintang\n","Data resizing and saving completed.\n","Data splitting completed for: temulawak\n","Data resizing and saving completed.\n","Data splitting completed for: jahe\n","Data resizing and saving completed.\n","Data splitting completed for: daun_salam\n","Data resizing and saving completed.\n","Data splitting completed for: biji_adas\n","Data resizing and saving completed.\n","Data splitting completed for: wijen\n","Data resizing and saving completed.\n","Data splitting completed for: asam_jawa\n","Data resizing and saving completed.\n","Data splitting completed for: pala\n","Data resizing and saving completed.\n","Data splitting completed for: kayu_manis\n","Data resizing and saving completed.\n","Data splitting completed for: vanili\n","Data resizing and saving completed.\n","Data splitting completed for: kayu_secang\n","Data resizing and saving completed.\n","Data splitting completed for: bawang_merah\n","Data resizing and saving completed.\n","Data splitting completed for: kencur\n"]}]},{"cell_type":"code","source":["def CheckTotalImages(folder_name, data_path):\n","    total_sum = 0\n","    for rootdir, dirs, files in os.walk(data_path):\n","        for subdir in dirs:\n","            path = os.path.join(rootdir, subdir)\n","            total_sum += len(os.listdir(path))\n","    print('Total Images in {}: {}'.format(folder_name, total_sum))\n","    return total_sum\n","\n","train_count = CheckTotalImages('Train', TRAIN_PATH)\n","dev_count = CheckTotalImages('Val', VAL_PATH)\n","total_count = train_count + dev_count\n","ratio_train = round(train_count / total_count, 4)\n","ratio_dev = round(dev_count / total_count, 4)\n","print('Total Images in Clean Dataset: {}\\nTrain Ratio: {}\\nDev Ratio: {}'.format(total_count, ratio_train, ratio_dev))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKy-KyL2MjWw","executionInfo":{"status":"ok","timestamp":1703125587051,"user_tz":-420,"elapsed":42,"user":{"displayName":"Annur Riyadhus Solikhin","userId":"05483728128707243037"}},"outputId":"4bf4147e-7949-46c1-ebad-5cf3bcec6406"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Images in Train: 1776\n","Total Images in Val: 764\n","Total Images in Clean Dataset: 2540\n","Train Ratio: 0.6992\n","Dev Ratio: 0.3008\n"]}]}]}